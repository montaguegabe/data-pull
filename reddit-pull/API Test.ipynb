{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests.auth\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = \"Test/0.1 by maxoboe\"\n",
    "def get_access_code(user_agent):\n",
    "    with open('account_info.txt', 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "        username = lines[0]\n",
    "        password = lines[1]\n",
    "        clientID = lines[2]\n",
    "        secretID = lines[3]\n",
    "    client_auth = requests.auth.HTTPBasicAuth(clientID, secretID)\n",
    "    post_data = {\"grant_type\": \"password\", \"username\": username, \"password\": password}\n",
    "    headers = {\"User-Agent\": user_agent}\n",
    "    response = requests.post(\"https://www.reddit.com/api/v1/access_token\", auth=client_auth, data=post_data, headers=headers)\n",
    "    return response.json()['access_token']\n",
    "def try_request(endpoint, access_token, headers, second_try=False):\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if 'error' in response.json():\n",
    "        if second_try:\n",
    "            return access_token, response\n",
    "        if response.json()['error'] == 401:\n",
    "            access_token = get_access_token(user_agent)\n",
    "            return try_request(endpoint, access_token, user_agent,second_try=True)\n",
    "    return access_token, response\n",
    "def format_row(child):\n",
    "    data = child['data']\n",
    "    title = data['title']\n",
    "    text = data['selftext']\n",
    "    url = data['url']\n",
    "    return {'title':title, 'text': text, 'url':url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = get_access_code(user_agent)\n",
    "headers = {\"Authorization\": \"bearer \" + access_token, \"User-Agent\": user_agent}\n",
    "query = \"climate+change\"\n",
    "endpoint = \"https://oauth.reddit.com/r/askscience/search?q=\" + query + \"&restrict_sr=on&sort=relevance&t=all&limit=100\"\n",
    "after = \"none\"\n",
    "with open('raw_queries.csv', 'w+', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['title', 'text', 'url']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    while after is not None:\n",
    "        access_token, response = try_request(endpoint + \"&after=\" + after, \n",
    "                                     access_token, headers)\n",
    "        after = response.json()['data']['after']\n",
    "        for child in response.json()['data']['children']:\n",
    "            writer.writerow(format_row(child))\n",
    "        time.sleep(1.1) #Rate limited to 60 requests per minute\n",
    "# Do this, but with after = after from first, count = count + 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

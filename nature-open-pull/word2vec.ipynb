{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import collection metadata\n",
        "import cPickle as pickle\n"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First take a peek at the data\n",
        "sentence_list = pickle.load(open('data-txt-insensitive2/nature05699.p'))"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentence_list)\n",
        "sentence_list[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": [
              "[u'a',\n",
              " u'firm',\n",
              " u'understanding',\n",
              " u'of',\n",
              " u'the',\n",
              " u'relationship',\n",
              " u'between',\n",
              " u'atmospheric',\n",
              " u'carbon',\n",
              " u'dioxide',\n",
              " u'concentration',\n",
              " u'and',\n",
              " u'temperature',\n",
              " u'is',\n",
              " u'critical',\n",
              " u'for',\n",
              " u'interpreting',\n",
              " u'past',\n",
              " u'climate',\n",
              " u'change',\n",
              " u'and',\n",
              " u'for',\n",
              " u'predicting',\n",
              " u'future',\n",
              " u'climate',\n",
              " u'change',\n",
              " u'',\n",
              " u'a',\n",
              " u'recent',\n",
              " u'synthesis',\n",
              " u'suggests',\n",
              " u'that',\n",
              " u'the',\n",
              " u'increase',\n",
              " u'in',\n",
              " u'global',\n",
              " u'mean',\n",
              " u'surface',\n",
              " u'temperature',\n",
              " u'in',\n",
              " u'response',\n",
              " u'to',\n",
              " u'a',\n",
              " u'doubling',\n",
              " u'of',\n",
              " u'the',\n",
              " u'atmospheric',\n",
              " u'carbon',\n",
              " u'dioxide',\n",
              " u'concentration',\n",
              " u'',\n",
              " u'termed',\n",
              " u'climate',\n",
              " u'sensitivity',\n",
              " u'',\n",
              " u'',\n",
              " u'is',\n",
              " u'between',\n",
              " 'TOKEN_NUMBER',\n",
              " u'and',\n",
              " 'TOKEN_NUMBER',\n",
              " u'c',\n",
              " u'',\n",
              " u'',\n",
              " u'',\n",
              " 'TOKEN_NUMBER',\n",
              " u'per',\n",
              " u'cent',\n",
              " u'likelihood',\n",
              " u'range',\n",
              " u'',\n",
              " u'',\n",
              " u'but',\n",
              " u'some',\n",
              " u'evidence',\n",
              " u'is',\n",
              " u'inconsistent',\n",
              " u'with',\n",
              " u'this',\n",
              " u'range',\n",
              " u'',\n",
              " u'',\n",
              " u'',\n",
              " u'',\n",
              " u'',\n",
              " u'moreover',\n",
              " u'',\n",
              " u'most',\n",
              " u'estimates',\n",
              " u'of',\n",
              " u'climate',\n",
              " u'sensitivity',\n",
              " u'are',\n",
              " u'based',\n",
              " u'on',\n",
              " u'records',\n",
              " u'of',\n",
              " u'climate',\n",
              " u'change',\n",
              " u'over',\n",
              " u'the',\n",
              " u'past',\n",
              " u'few',\n",
              " u'decades',\n",
              " u'to',\n",
              " u'thousands',\n",
              " u'of',\n",
              " u'years',\n",
              " u'',\n",
              " u'when',\n",
              " u'carbon',\n",
              " u'dioxide',\n",
              " u'concentrations',\n",
              " u'and',\n",
              " u'global',\n",
              " u'temperatures',\n",
              " u'were',\n",
              " u'similar',\n",
              " u'to',\n",
              " u'or',\n",
              " u'lower',\n",
              " u'than',\n",
              " u'today',\n",
              " u'',\n",
              " u'',\n",
              " u'so',\n",
              " u'such',\n",
              " u'calculations',\n",
              " u'tend',\n",
              " u'to',\n",
              " u'underestimate',\n",
              " u'the',\n",
              " u'magnitude',\n",
              " u'of',\n",
              " u'large',\n",
              " u'climate',\n",
              " u'change',\n",
              " u'events',\n",
              " u'and',\n",
              " u'may',\n",
              " u'not',\n",
              " u'be',\n",
              " u'applicable',\n",
              " u'to',\n",
              " u'climate',\n",
              " u'change',\n",
              " u'under',\n",
              " u'warmer',\n",
              " u'conditions',\n",
              " u'in',\n",
              " u'the',\n",
              " u'future',\n",
              " u'',\n",
              " u'here',\n",
              " u'we',\n",
              " u'estimate',\n",
              " u'long',\n",
              " u'term',\n",
              " u'equilibrium',\n",
              " u'climate',\n",
              " u'sensitivity',\n",
              " u'by',\n",
              " u'modelling',\n",
              " u'carbon',\n",
              " u'dioxide',\n",
              " u'concentrations',\n",
              " u'over',\n",
              " u'the',\n",
              " u'past',\n",
              " 'TOKEN_NUMBER',\n",
              " u'million',\n",
              " u'years',\n",
              " u'and',\n",
              " u'comparing',\n",
              " u'our',\n",
              " u'calculations',\n",
              " u'with',\n",
              " u'a',\n",
              " u'proxy',\n",
              " u'record',\n",
              " u'',\n",
              " u'our',\n",
              " u'estimates',\n",
              " u'are',\n",
              " u'broadly',\n",
              " u'consistent',\n",
              " u'with',\n",
              " u'estimates',\n",
              " u'based',\n",
              " u'on',\n",
              " u'short',\n",
              " u'term',\n",
              " u'climate',\n",
              " u'records',\n",
              " u'',\n",
              " u'and',\n",
              " u'indicate',\n",
              " u'that',\n",
              " u'a',\n",
              " u'weak',\n",
              " u'radiative',\n",
              " u'forcing',\n",
              " u'by',\n",
              " u'carbon',\n",
              " u'dioxide',\n",
              " u'is',\n",
              " u'highly',\n",
              " u'unlikely',\n",
              " u'on',\n",
              " u'multi',\n",
              " u'million',\n",
              " u'year',\n",
              " u'timescales',\n",
              " u'',\n",
              " u'we',\n",
              " u'conclude',\n",
              " u'that',\n",
              " u'a',\n",
              " u'climate',\n",
              " u'sensitivity',\n",
              " u'greater',\n",
              " u'than',\n",
              " 'TOKEN_NUMBER',\n",
              " u'c',\n",
              " u'has',\n",
              " u'probably',\n",
              " u'been',\n",
              " u'a',\n",
              " u'robust',\n",
              " u'feature',\n",
              " u'of',\n",
              " u'the',\n",
              " u'earth',\n",
              " u's',\n",
              " u'climate',\n",
              " u'system',\n",
              " u'over',\n",
              " u'the',\n",
              " u'past',\n",
              " 'TOKEN_NUMBER',\n",
              " u'million',\n",
              " u'years',\n",
              " u'',\n",
              " u'regardless',\n",
              " u'of',\n",
              " u'temporal',\n",
              " u'scaling',\n",
              " u'']"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cPickle as pickle\n",
        "\n",
        "# Define an iterator for streaming the pickle files\n",
        "class DirectorySentenceIterator:\n",
        "    def __init__(self, start, at_a_time, filedir):\n",
        "        self.batch_index = start # global index of start of batch\n",
        "        self.at_a_time = at_a_time\n",
        "        \n",
        "        # Get list of files in directory\n",
        "        self.file_list = [f for f in listdir(filedir) if isfile(join(filedir, f))]\n",
        "\n",
        "        self.batch = []\n",
        "        self.filedir = filedir\n",
        "        self.index = 0 # within the batch\n",
        "        self.last = False\n",
        "        self._update_batch()\n",
        "\n",
        "    # Makes use of the current index to update the batch\n",
        "    def _update_batch(self):\n",
        "\n",
        "        self.batch = []\n",
        "        \n",
        "        end_ind = self.batch_index + self.at_a_time\n",
        "        if end_ind >= len(self.file_list):\n",
        "            end_ind = len(self.file_list)\n",
        "            self.last = True\n",
        "        batch_files = self.file_list[self.batch_index:end_ind]\n",
        "        \n",
        "        for fname in batch_files:\n",
        "            sentences = pickle.load(open(join(self.filedir, fname), 'rb'))\n",
        "            self.batch.extend(sentences)\n",
        "            \n",
        "        if len(self.batch) == 0:\n",
        "            if not self.last:\n",
        "                self.batch_index += self.at_a_time\n",
        "                self._update_batch()\n",
        "            else:\n",
        "                raise StopIteration\n",
        "        \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def next(self):\n",
        "        if self.index >= len(self.batch):\n",
        "            if self.last:\n",
        "                raise StopIteration\n",
        "            else:\n",
        "                self.index = 0\n",
        "                self.batch_index += self.at_a_time\n",
        "                self._update_batch()\n",
        "        self.index += 1\n",
        "        return self.batch[self.index - 1]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dsi = DirectorySentenceIterator(0, 10000, './data-txt-insensitive')\n",
        "hack = []\n",
        "for sentence_list in dsi:\n",
        "    hack.append(sentence_list)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging, gensim\n",
        "from gensim.models import word2vec\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = word2vec.Word2Vec(hack, size=50, window=10, min_count=5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('word2vec_txt_insensitive.m')\n",
        "model = word2vec.Word2Vec.load('word2vec_txt_insensitive.m')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-28 01:52:57,793 : INFO : loading Word2Vec object from word2vec_txt_insensitive.m\n",
            "2018-02-28 01:52:57,998 : INFO : loading wv recursively from word2vec_txt_insensitive.m.wv.* with mmap=None\n",
            "2018-02-28 01:52:58,002 : INFO : setting ignored attribute syn0norm to None\n",
            "2018-02-28 01:52:58,003 : INFO : setting ignored attribute cum_table to None\n",
            "2018-02-28 01:52:58,004 : INFO : loaded word2vec_txt_insensitive.m\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv['rain']\n",
        "#model.wv.most_similar('ocean')\n",
        "model.wv.most_similar('china')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-28 01:53:03,074 : INFO : precomputing L2-norms of word weight vectors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": [
              "[(u'india', 0.7654091119766235),\n",
              " (u'nigeria', 0.7598310708999634),\n",
              " (u'India', 0.7591868042945862),\n",
              " (u'Pakistan', 0.7487422823905945),\n",
              " (u'brazil', 0.741621732711792),\n",
              " (u'pakistan', 0.739411473274231),\n",
              " (u'Indonesia', 0.7333608269691467),\n",
              " (u'Cuba', 0.7291191816329956),\n",
              " (u'indonesia', 0.7280763387680054),\n",
              " (u'bangladesh', 0.7261566519737244)]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = list(model.wv.vocab)\n",
        "X = model[vocab]"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tsne = TSNE(n_components=2)\n",
        "X_tsne = tsne.fit_transform(X)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(tsne, open('X_tsne_simple.p', 'wb'))\n",
        "#X_tsne = pickle.load(open('X_tsne_simple.p', 'rb'))"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(X_tsne, index=vocab, columns=['x', 'y'])\n",
        "df.to_csv('X_tsne.csv')"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patheffects as path_effects\n",
        "reload(path_effects)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": [
              "<module 'matplotlib.patheffects' from '/anaconda2/envs/earthdata/lib/python2.7/site-packages/matplotlib/patheffects.pyc'>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(8, 6), dpi=150)\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "ax.scatter(df['x'], df['y'], c='cyan', alpha=0.25)\n",
        "ax.set_facecolor('black')\n",
        "\n",
        "#idx = 6\n",
        "idx = 2\n",
        "\n",
        "for word, pos in df.iterrows():\n",
        "    #idx += 1\n",
        "    idx += 1\n",
        "    if idx % 160 != 0:\n",
        "        continue\n",
        "    \n",
        "    ax.annotate(word, pos, color='white', fontweight='bold')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<matplotlib.figure.Figure at 0x1a1fac1510>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig.savefig('MINE')"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time for doc2vec"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import doc2vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "# We need to feed it labeled sentences\n",
        "idx = 0\n",
        "doc_sentences = []\n",
        "for sentence_list in sentences:\n",
        "    \n",
        "    ln = metadata[idx]['Collection']['LongName']\n",
        "    \n",
        "    for sentence in sentence_list:\n",
        "        ls = TaggedDocument(words=filter(None, sentence.split(' ')), tags=[unicode(idx), ln])\n",
        "        doc_sentences.append(ls)\n",
        "        \n",
        "    idx += 1\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_sentences[0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = doc2vec.Doc2Vec(doc_sentences, size=100, window=8, min_count=5, workers=7)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('doc2vec_structured.m')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets see which is the most similiar to a chosen document\n",
        "\nmodel.docvecs.most_similar(200) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print metadata[200]['Collection']['ShortName']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This works, but what would have happened if we had used a different representation of documents that captured less of the structure?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "# Parallelize for speed\n",
        "pool = multiprocessing.Pool()\n",
        "documents = pool.map(struct2Doc, metadata)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import doc2vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "# We need to feed it labeled sentences\n",
        "idx = 0\n",
        "doc_sentences2 = []\n",
        "for document in documents:\n",
        "    ln = metadata[idx]['Collection']['LongName']\n",
        "    sentence = filter(None, document.split(' '))\n",
        "    td = TaggedDocument(words=sentence, tags=[unicode(idx), ln])\n",
        "    doc_sentences2.append(td)\n",
        "    idx += 1"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_simplified = doc2vec.Doc2Vec(doc_sentences2, size=100, window=8, min_count=5, workers=7)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_simplified.save('doc2vec_simple.m')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare how this version of documents compares"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_simplified.docvecs.most_similar(200) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.docvecs.most_similar(200)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks about the same."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use LDA on the data. First we have to make a corpus."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "\n",
        "plain_sentences = [filter(None, document.split(' ')) for document in documents]\n",
        "dictionary = corpora.Dictionary(plain_sentences)\n",
        "corpus = [dictionary.doc2bow(sentence) for sentence in plain_sentences]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=100, id2word=dictionary)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda.print_topics(10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda.save('lda_simple.m')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "language": "python",
      "display_name": "Python 2"
    },
    "kernel_info": {
      "name": "python2"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.14",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    },
    "nteract": {
      "version": "0.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
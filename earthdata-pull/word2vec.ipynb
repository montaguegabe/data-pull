{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook relies on sampling from the `sample.ipynb` notebook. We will extract metadata descriptions, then fit models on them."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Import collection metadata\n",
        "import pickle\n",
        "long_names, metadata = pickle.load(open('metadata.p', 'rb'))"
      ],
      "outputs": [],
      "execution_count": 135,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now need to make a small corpus. First naive strategy: concatenate all the leaves of the structure in random order.\n",
        "\nNOTE: this discards important information along the paths to the leaves."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# source: https://stackoverflow.com/questions/12507206/python-recommended-way-to-walk-complex-dictionary-structures-imported-from-json\n",
        "\n",
        "# This code turns a dictionary into a list of paths to leaves\n",
        "def dict_generator(indict, pre=None):\n",
        "    pre = pre[:] if pre else []\n",
        "    if isinstance(indict, dict):\n",
        "        for key, value in indict.items():\n",
        "            if isinstance(value, dict):\n",
        "                for d in dict_generator(value, [key] + pre):\n",
        "                    yield d\n",
        "            elif isinstance(value, list) or isinstance(value, tuple):\n",
        "                for v in value:\n",
        "                    for d in dict_generator(v, [key] + pre):\n",
        "                        yield d\n",
        "            else:\n",
        "                yield pre + [key, value]\n",
        "    else:\n",
        "        yield indict"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source: https://stackoverflow.com/questions/354038/how-do-i-check-if-a-string-is-a-number-float\n",
        "def is_number(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WARNING: Naive implementation\n",
        "def struct2Doc(cln):\n",
        "    # Convert to javascript-style dictionary-array object\n",
        "    hierarchy = json.loads(json.dumps(cln))\n",
        "\n",
        "    path_gen = dict_generator(hierarchy)\n",
        "    leaves = []\n",
        "\n",
        "    for path in path_gen:\n",
        "        leaf = path[-1]\n",
        "\n",
        "        # Do some filtering on the leaves (see below)\n",
        "        if leaf == '' or leaf == None:\n",
        "            continue\n",
        "        if is_number(leaf):\n",
        "            continue\n",
        "        if validators.url(leaf):\n",
        "            continue\n",
        "\n",
        "        # TODO: Extend\n",
        "        leaf = re.sub(r'[^\\s\\w]+', ' ', leaf)\n",
        "        #print leaf\n",
        "        leaves.append(leaf.lower())\n",
        "\n",
        "    # Shuffle so that incidental proximity of leaves to eachother is not taken into account\n",
        "    shuffle(leaves)\n",
        "    document = ' '.join(leaves)\n",
        "    \n",
        "    return document\n",
        "\n",
        "# Just from looking at the result it seems we should filter out:\n",
        "#  - Empty leaves\n",
        "#  - Numbers\n",
        "#  - URL's and emails\n",
        "#  - Dates?\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 212,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# WARNING: This may be too reliant on structured data\n",
        "\n",
        "# Structured output\n",
        "def struct2Sentence(cln):\n",
        "    # Convert to javascript-style dictionary-array object\n",
        "    hierarchy = json.loads(json.dumps(cln))\n",
        "\n",
        "    path_gen = dict_generator(hierarchy)\n",
        "    sentences = []\n",
        "\n",
        "    for path in path_gen:\n",
        "        leaf = path[-1]\n",
        "\n",
        "        # Do some filtering on the leaves (see below)\n",
        "        if leaf == '' or leaf == None:\n",
        "            continue\n",
        "        if is_number(leaf):\n",
        "            continue\n",
        "        if validators.url(leaf):\n",
        "            continue\n",
        "\n",
        "        sentence = ' '.join(path)\n",
        "        \n",
        "        # Make sentence lowercase and remove periods\n",
        "        sentence = re.sub(r'[^\\s\\w]+', ' ', sentence)\n",
        "        sentences.append(sentence.lower())\n",
        "    \n",
        "    return sentences\n",
        "\n",
        "# Just from looking at the result it seems we should filter out:\n",
        "#  - Empty leaves\n",
        "#  - Numbers\n",
        "#  - URL's and emails\n",
        "#  - Dates?\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 213,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cln = metadata[0]\n",
        "document = struct2Sentence(cln)\n",
        "print document"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[u'concept id c1000000000 cddis', u'instrument instruments platform platforms collection shortname doris receiver', u'platform platforms collection shortname cryosat 2', u'platform platforms collection type  ', u'platform platforms collection longname cryosat 2', u'instrument instruments platform platforms collection shortname doris beacon', u'platform platforms collection shortname ground stations', u'platform platforms collection type  ', u'platform platforms collection longname ground stations', u'instrument instruments platform platforms collection shortname doris receiver', u'platform platforms collection shortname hy 2a', u'platform platforms collection type  ', u'platform platforms collection longname haiyang 2a', u'instrument instruments platform platforms collection shortname doris receiver', u'platform platforms collection shortname jason 1', u'platform platforms collection type  ', u'platform platforms collection longname jason 1', u'instrument instruments platform platforms collection shortname doris receiver', u'platform platforms collection shortname jason 2', u'platform platforms collection type  ', u'platform platforms collection longname jason 2', u'instrument instruments platform platforms collection shortname doris receiver', u'platform platforms collection shortname spot 2', u'platform platforms collection type  ', u'platform platforms collection longname systeme probatoire pour l observation de la terre 2', u'instrument instruments platform platforms collection shortname doris receiver', u'platform platforms collection shortname spot 3', u'platform platforms collection type  ', u'platform platforms collection longname systeme probatoire pour l observation de la terre 3', u'instrument instruments platform platforms collection shortname doris receiver', u'platform platforms collection shortname spot 4', u'platform platforms collection type  ', u'platform platforms collection longname systeme probatoire pour l observation de la terre 4', u'instrument instruments platform platforms collection shortname doris receiver', u'platform platforms collection shortname spot 5', u'platform platforms collection type  ', u'platform platforms collection longname systeme probatoire pour l observation de la terre 5', u'instrument instruments platform platforms collection shortname doris receiver', u'platform platforms collection shortname topex poseidon', u'platform platforms collection type  ', u'platform platforms collection longname ocean topography experiment', u'collection lastupdate 2012 05 31t00 00 00', u'collection description the doppler orbitography by radiopositioning integrated on satellite  doris  was developed by the centre national d etudes spatiales  cnes  with cooperation from other french government agencies  the system was developed to provide precise orbit determination and high accuracy location of ground beacons for point positioning  doris is a dual frequency doppler system that has been included as an experiment on various space missions such as topex poseidon  spot 2   3   4  and  5  envisat  and jason satellites  unlike many other navigation systems  doris is based on an uplink device  the receivers are on board the satellite with the transmitters are on the ground  this creates a centralized system in which the complete set of observations is downloaded by the satellite to the ground center  from where they are distributed after editing and processing  an accurate measurment is made of the doppler shift on radiofrequency signals emitted by the ground beacons and received on the spacecraft ', u'contact contacts collection organizationname crustal dynamics data information system', u'phone organizationphones contact contacts collection type telephone', u'phone organizationphones contact contacts collection number 301 614 6542', u'phone organizationphones contact contacts collection type fax', u'phone organizationphones contact contacts collection number 301 614 6015', u'address organizationaddresses contact contacts collection city greenbelt', u'address organizationaddresses contact contacts collection streetaddress nasa goddard space flight center  code 690', u'address organizationaddresses contact contacts collection stateprovince md', u'address organizationaddresses contact contacts collection country usa', u'contactperson contactpersons contact contacts collection lastname noll', u'contactperson contactpersons contact contacts collection firstname carey', u'contact contacts collection role archiver', u'organizationemails contact contacts collection email carey e noll nasa gov', u'temporal collection endsatpresentflag true', u'rangedatetime temporal collection beginningdatetime 1990 03 31t00 00 00', u'campaign campaigns collection shortname ids', u'campaign campaigns collection longname international doris service', u'collection longname doppler orbitography by radiopositioning integrated on satellite range rate observation data  cycle format  from nasa cddis', u'collection inserttime 2003 01 23t17 00 00', u'geometry horizontalspatialdomain spatial collection coordinatesystem cartesian', u'spatial collection granulespatialrepresentation cartesian', u'verticalspatialdomain spatial collection type none', u'verticalspatialdomain spatial collection value none', u'collection shortname cddis_doris_data_cycle', u'collection archivecenter cddis gsfc', u'collection datasetid cddis_doris_data_cycle', u'dif associateddifs collection entryid cddis_doris_data', u'format application echo10 xml']\n"
          ]
        }
      ],
      "execution_count": 216,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to convert collections in-bulk to documents"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "# Parallelize for speed\n",
        "pool = multiprocessing.Pool()\n",
        "#documents = pool.map(struct2Doc, metadata)\n",
        "sentences = pool.map(struct2Sentence, metadata)\n",
        "\nsentences[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 154,
          "data": {
            "text/plain": [
              "[u'conceptid c1000000000cddis',\n",
              " u'collection lastupdate 20120531t000000',\n",
              " u'collection description the doppler orbitography by radiopositioning integrated on satellite doris was developed by the centre national detudes spatiales cnes with cooperation from other french government agencies the system was developed to provide precise orbit determination and high accuracy location of ground beacons for point positioning doris is a dualfrequency doppler system that has been included as an experiment on various space missions such as topexposeidon spot2 3 4 and 5 envisat and jason satellites unlike many other navigation systems doris is based on an uplink device the receivers are on board the satellite with the transmitters are on the ground this creates a centralized system in which the complete set of observations is downloaded by the satellite to the ground center from where they are distributed after editing and processing an accurate measurment is made of the doppler shift on radiofrequency signals emitted by the ground beacons and received on the spacecraft',\n",
              " u'contact contacts collection organizationname crustal dynamics data information system',\n",
              " u'phone organizationphones contact contacts collection type telephone',\n",
              " u'phone organizationphones contact contacts collection number 3016146542',\n",
              " u'phone organizationphones contact contacts collection type fax',\n",
              " u'phone organizationphones contact contacts collection number 3016146015',\n",
              " u'address organizationaddresses contact contacts collection city greenbelt',\n",
              " u'address organizationaddresses contact contacts collection streetaddress nasa goddard space flight center code 690',\n",
              " u'address organizationaddresses contact contacts collection stateprovince md',\n",
              " u'address organizationaddresses contact contacts collection country usa',\n",
              " u'contactperson contactpersons contact contacts collection lastname noll',\n",
              " u'contactperson contactpersons contact contacts collection firstname carey',\n",
              " u'contact contacts collection role archiver',\n",
              " u'organizationemails contact contacts collection email careyenollnasagov',\n",
              " u'temporal collection endsatpresentflag true',\n",
              " u'rangedatetime temporal collection beginningdatetime 19900331t000000',\n",
              " u'geometry horizontalspatialdomain spatial collection coordinatesystem cartesian',\n",
              " u'spatial collection granulespatialrepresentation cartesian',\n",
              " u'verticalspatialdomain spatial collection type none',\n",
              " u'verticalspatialdomain spatial collection value none',\n",
              " u'campaign campaigns collection shortname ids',\n",
              " u'campaign campaigns collection longname international doris service',\n",
              " u'instrument instruments platform platforms collection shortname doris receiver',\n",
              " u'platform platforms collection shortname cryosat2',\n",
              " u'platform platforms collection type  ',\n",
              " u'platform platforms collection longname cryosat2',\n",
              " u'instrument instruments platform platforms collection shortname doris beacon',\n",
              " u'platform platforms collection shortname ground stations',\n",
              " u'platform platforms collection type  ',\n",
              " u'platform platforms collection longname ground stations',\n",
              " u'instrument instruments platform platforms collection shortname doris receiver',\n",
              " u'platform platforms collection shortname hy2a',\n",
              " u'platform platforms collection type  ',\n",
              " u'platform platforms collection longname haiyang2a',\n",
              " u'instrument instruments platform platforms collection shortname doris receiver',\n",
              " u'platform platforms collection shortname jason1',\n",
              " u'platform platforms collection type  ',\n",
              " u'platform platforms collection longname jason1',\n",
              " u'instrument instruments platform platforms collection shortname doris receiver',\n",
              " u'platform platforms collection shortname jason2',\n",
              " u'platform platforms collection type  ',\n",
              " u'platform platforms collection longname jason2',\n",
              " u'instrument instruments platform platforms collection shortname doris receiver',\n",
              " u'platform platforms collection shortname spot2',\n",
              " u'platform platforms collection type  ',\n",
              " u'platform platforms collection longname systeme probatoire pour lobservation de la terre2',\n",
              " u'instrument instruments platform platforms collection shortname doris receiver',\n",
              " u'platform platforms collection shortname spot3',\n",
              " u'platform platforms collection type  ',\n",
              " u'platform platforms collection longname systeme probatoire pour lobservation de la terre3',\n",
              " u'instrument instruments platform platforms collection shortname doris receiver',\n",
              " u'platform platforms collection shortname spot4',\n",
              " u'platform platforms collection type  ',\n",
              " u'platform platforms collection longname systeme probatoire pour lobservation de la terre4',\n",
              " u'instrument instruments platform platforms collection shortname doris receiver',\n",
              " u'platform platforms collection shortname spot5',\n",
              " u'platform platforms collection type  ',\n",
              " u'platform platforms collection longname systeme probatoire pour lobservation de la terre5',\n",
              " u'instrument instruments platform platforms collection shortname doris receiver',\n",
              " u'platform platforms collection shortname topexposeidon',\n",
              " u'platform platforms collection type  ',\n",
              " u'platform platforms collection longname ocean topography experiment',\n",
              " u'collection inserttime 20030123t170000',\n",
              " u'collection longname doppler orbitography by radiopositioning integrated on satellite rangerate observation data cycle format from nasa cddis',\n",
              " u'collection shortname cddis_doris_data_cycle',\n",
              " u'collection archivecenter cddisgsfc',\n",
              " u'collection datasetid cddis_doris_data_cycle',\n",
              " u'dif associateddifs collection entryid cddis_doris_data',\n",
              " u'format applicationecho10xml']"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 154,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flattenGenerator(listOfLists):\n",
        "    for list2 in listOfLists:\n",
        "        for item in list2:\n",
        "            yield item\n",
        "\n",
        "sentenceGen = flattenGenerator(sentences)\n",
        "sentenceGen.next()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 123,
          "data": {
            "text/plain": [
              "u'conceptid c1000000000cddis'"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 123,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For word2vec we need just a list of sentences"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_flat = [filter(None, item.split(' ')) for sublist in sentences for item in sublist]"
      ],
      "outputs": [],
      "execution_count": 124,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can examine document similarity between collection metadata."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging, gensim\n",
        "from gensim.models import word2vec\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "outputs": [],
      "execution_count": 125,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try word2vec on sentences"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = word2vec.Word2Vec(sentences_flat, size=100, window=5, min_count=5, workers=7)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-13 20:44:09,022 : INFO : collecting all words and their counts\n",
            "2018-02-13 20:44:09,026 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2018-02-13 20:44:09,072 : INFO : PROGRESS: at sentence #10000, processed 78389 words, keeping 4601 word types\n",
            "2018-02-13 20:44:09,120 : INFO : PROGRESS: at sentence #20000, processed 162222 words, keeping 7006 word types\n",
            "2018-02-13 20:44:09,166 : INFO : PROGRESS: at sentence #30000, processed 239825 words, keeping 9093 word types\n",
            "2018-02-13 20:44:09,215 : INFO : PROGRESS: at sentence #40000, processed 325109 words, keeping 9797 word types\n",
            "2018-02-13 20:44:09,265 : INFO : PROGRESS: at sentence #50000, processed 404400 words, keeping 12067 word types\n",
            "2018-02-13 20:44:09,321 : INFO : PROGRESS: at sentence #60000, processed 490160 words, keeping 14474 word types\n",
            "2018-02-13 20:44:09,369 : INFO : PROGRESS: at sentence #70000, processed 573714 words, keeping 16293 word types\n",
            "2018-02-13 20:44:09,422 : INFO : PROGRESS: at sentence #80000, processed 664956 words, keeping 18947 word types\n",
            "2018-02-13 20:44:09,476 : INFO : PROGRESS: at sentence #90000, processed 749412 words, keeping 20292 word types\n",
            "2018-02-13 20:44:09,523 : INFO : PROGRESS: at sentence #100000, processed 831275 words, keeping 21719 word types\n",
            "2018-02-13 20:44:09,580 : INFO : PROGRESS: at sentence #110000, processed 914072 words, keeping 23248 word types\n",
            "2018-02-13 20:44:09,637 : INFO : PROGRESS: at sentence #120000, processed 1005032 words, keeping 25266 word types\n",
            "2018-02-13 20:44:09,687 : INFO : PROGRESS: at sentence #130000, processed 1094518 words, keeping 27226 word types\n",
            "2018-02-13 20:44:09,733 : INFO : PROGRESS: at sentence #140000, processed 1179361 words, keeping 28311 word types\n",
            "2018-02-13 20:44:09,780 : INFO : PROGRESS: at sentence #150000, processed 1258249 words, keeping 29181 word types\n",
            "2018-02-13 20:44:09,826 : INFO : PROGRESS: at sentence #160000, processed 1337527 words, keeping 30117 word types\n",
            "2018-02-13 20:44:09,874 : INFO : PROGRESS: at sentence #170000, processed 1424080 words, keeping 30895 word types\n",
            "2018-02-13 20:44:09,920 : INFO : PROGRESS: at sentence #180000, processed 1504057 words, keeping 32078 word types\n",
            "2018-02-13 20:44:09,966 : INFO : PROGRESS: at sentence #190000, processed 1578212 words, keeping 33336 word types\n",
            "2018-02-13 20:44:10,014 : INFO : PROGRESS: at sentence #200000, processed 1656174 words, keeping 34259 word types\n",
            "2018-02-13 20:44:10,061 : INFO : PROGRESS: at sentence #210000, processed 1737901 words, keeping 34991 word types\n",
            "2018-02-13 20:44:10,117 : INFO : PROGRESS: at sentence #220000, processed 1825135 words, keeping 36126 word types\n",
            "2018-02-13 20:44:10,165 : INFO : PROGRESS: at sentence #230000, processed 1908942 words, keeping 38158 word types\n",
            "2018-02-13 20:44:10,216 : INFO : PROGRESS: at sentence #240000, processed 1989490 words, keeping 39625 word types\n",
            "2018-02-13 20:44:10,233 : INFO : collected 40100 word types from a corpus of 2016486 raw words and 243133 sentences\n",
            "2018-02-13 20:44:10,234 : INFO : Loading a fresh vocabulary\n",
            "2018-02-13 20:44:10,307 : INFO : min_count=5 retains 9179 unique words (22% of original 40100, drops 30921)\n",
            "2018-02-13 20:44:10,309 : INFO : min_count=5 leaves 1970647 word corpus (97% of original 2016486, drops 45839)\n",
            "2018-02-13 20:44:10,346 : INFO : deleting the raw counts dictionary of 40100 items\n",
            "2018-02-13 20:44:10,348 : INFO : sample=0.001 downsamples 58 most-common words\n",
            "2018-02-13 20:44:10,352 : INFO : downsampling leaves estimated 1258375 word corpus (63.9% of prior 1970647)\n",
            "2018-02-13 20:44:10,353 : INFO : estimated required memory for 9179 words and 100 dimensions: 11932700 bytes\n",
            "2018-02-13 20:44:10,395 : INFO : resetting layer weights\n",
            "2018-02-13 20:44:10,516 : INFO : training model with 7 workers on 9179 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2018-02-13 20:44:11,526 : INFO : PROGRESS: at 14.94% examples, 948837 words/s, in_qsize 1, out_qsize 0\n",
            "2018-02-13 20:44:12,534 : INFO : PROGRESS: at 29.99% examples, 939839 words/s, in_qsize 0, out_qsize 0\n",
            "2018-02-13 20:44:13,545 : INFO : PROGRESS: at 45.63% examples, 947965 words/s, in_qsize 0, out_qsize 2\n",
            "2018-02-13 20:44:14,539 : INFO : PROGRESS: at 60.84% examples, 951633 words/s, in_qsize 0, out_qsize 0\n",
            "2018-02-13 20:44:15,544 : INFO : PROGRESS: at 75.49% examples, 947353 words/s, in_qsize 0, out_qsize 0\n",
            "2018-02-13 20:44:16,562 : INFO : PROGRESS: at 89.70% examples, 934853 words/s, in_qsize 0, out_qsize 2\n",
            "2018-02-13 20:44:17,233 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2018-02-13 20:44:17,235 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2018-02-13 20:44:17,239 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2018-02-13 20:44:17,241 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-02-13 20:44:17,242 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-02-13 20:44:17,244 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-02-13 20:44:17,245 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-02-13 20:44:17,247 : INFO : training on 10082430 raw words (6291099 effective words) took 6.7s, 935762 effective words/s\n"
          ]
        }
      ],
      "execution_count": 126,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('word2vec_structured.m')\n",
        "#model = word2vec.load('simple_model.m')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-13 20:44:21,460 : INFO : saving Word2Vec object under simple_model.m, separately None\n",
            "2018-02-13 20:44:21,465 : INFO : not storing attribute syn0norm\n",
            "2018-02-13 20:44:21,466 : INFO : not storing attribute cum_table\n",
            "2018-02-13 20:44:21,580 : INFO : saved simple_model.m\n"
          ]
        }
      ],
      "execution_count": 127,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv['rain']\n",
        "model.wv.most_similar('rainfall')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 133,
          "data": {
            "text/plain": [
              "[(u'measurement', 0.7558643817901611),\n",
              " (u'ii', 0.7248314619064331),\n",
              " (u'iii', 0.7035893797874451),\n",
              " (u'islscp', 0.685666024684906),\n",
              " (u'fire', 0.6785022616386414),\n",
              " (u'convection', 0.6691360473632812),\n",
              " (u'transcom', 0.6663325428962708),\n",
              " (u'measuring', 0.6540623903274536),\n",
              " (u'tropical', 0.6412253379821777),\n",
              " (u'icesat', 0.6358033418655396)]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 133,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time for doc2vec"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import doc2vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "# We need to feed it labeled sentences\n",
        "idx = 0\n",
        "doc_sentences = []\n",
        "for sentence_list in sentences:\n",
        "    \n",
        "    ln = metadata[idx]['Collection']['LongName']\n",
        "    \n",
        "    for sentence in sentence_list:\n",
        "        ls = TaggedDocument(words=filter(None, sentence.split(' ')), tags=[unicode(idx), ln])\n",
        "        doc_sentences.append(ls)\n",
        "        \n",
        "    idx += 1\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 186,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_sentences[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 187,
          "data": {
            "text/plain": [
              "TaggedDocument(words=[u'conceptid', u'c1000000000cddis'], tags=[u'0', 'Doppler Orbitography by Radiopositioning Integrated on Satellite Range-Rate Observation Data (cycle format) from NASA CDDIS'])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 187,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = doc2vec.Doc2Vec(doc_sentences, size=100, window=8, min_count=5, workers=7)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-13 23:40:50,596 : INFO : collecting all words and their counts\n",
            "2018-02-13 23:40:50,598 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
            "2018-02-13 23:40:50,767 : INFO : PROGRESS: at example #10000, processed 78389 words (467134/s), 4601 word types, 146 tags\n",
            "2018-02-13 23:40:50,931 : INFO : PROGRESS: at example #20000, processed 162222 words (522203/s), 7006 word types, 245 tags\n",
            "2018-02-13 23:40:51,095 : INFO : PROGRESS: at example #30000, processed 239825 words (478516/s), 9093 word types, 305 tags\n",
            "2018-02-13 23:40:51,259 : INFO : PROGRESS: at example #40000, processed 325109 words (524534/s), 9797 word types, 425 tags\n",
            "2018-02-13 23:40:51,426 : INFO : PROGRESS: at example #50000, processed 404400 words (479667/s), 12067 word types, 583 tags\n",
            "2018-02-13 23:40:51,588 : INFO : PROGRESS: at example #60000, processed 490160 words (536476/s), 14474 word types, 722 tags\n",
            "2018-02-13 23:40:51,748 : INFO : PROGRESS: at example #70000, processed 573714 words (525956/s), 16293 word types, 908 tags\n",
            "2018-02-13 23:40:51,919 : INFO : PROGRESS: at example #80000, processed 664956 words (536787/s), 18947 word types, 1081 tags\n",
            "2018-02-13 23:40:52,080 : INFO : PROGRESS: at example #90000, processed 749412 words (531290/s), 20292 word types, 1262 tags\n",
            "2018-02-13 23:40:52,241 : INFO : PROGRESS: at example #100000, processed 831275 words (513173/s), 21719 word types, 1457 tags\n",
            "2018-02-13 23:40:52,426 : INFO : PROGRESS: at example #110000, processed 914072 words (457194/s), 23248 word types, 1581 tags\n",
            "2018-02-13 23:40:52,599 : INFO : PROGRESS: at example #120000, processed 1005032 words (539850/s), 25266 word types, 1749 tags\n",
            "2018-02-13 23:40:52,766 : INFO : PROGRESS: at example #130000, processed 1094518 words (549185/s), 27226 word types, 1915 tags\n",
            "2018-02-13 23:40:52,937 : INFO : PROGRESS: at example #140000, processed 1179361 words (499829/s), 28311 word types, 2076 tags\n",
            "2018-02-13 23:40:53,099 : INFO : PROGRESS: at example #150000, processed 1258249 words (493271/s), 29181 word types, 2222 tags\n",
            "2018-02-13 23:40:53,253 : INFO : PROGRESS: at example #160000, processed 1337527 words (519130/s), 30117 word types, 2406 tags\n",
            "2018-02-13 23:40:53,414 : INFO : PROGRESS: at example #170000, processed 1424080 words (541901/s), 30895 word types, 2517 tags\n",
            "2018-02-13 23:40:53,588 : INFO : PROGRESS: at example #180000, processed 1504057 words (464701/s), 32078 word types, 2597 tags\n",
            "2018-02-13 23:40:53,765 : INFO : PROGRESS: at example #190000, processed 1578212 words (421376/s), 33336 word types, 2750 tags\n",
            "2018-02-13 23:40:53,929 : INFO : PROGRESS: at example #200000, processed 1656174 words (479627/s), 34259 word types, 2843 tags\n",
            "2018-02-13 23:40:54,090 : INFO : PROGRESS: at example #210000, processed 1737901 words (514971/s), 34991 word types, 2921 tags\n",
            "2018-02-13 23:40:54,253 : INFO : PROGRESS: at example #220000, processed 1825135 words (538484/s), 36126 word types, 3023 tags\n",
            "2018-02-13 23:40:54,417 : INFO : PROGRESS: at example #230000, processed 1908942 words (517406/s), 38158 word types, 3151 tags\n",
            "2018-02-13 23:40:54,591 : INFO : PROGRESS: at example #240000, processed 1989490 words (466341/s), 39625 word types, 3353 tags\n",
            "2018-02-13 23:40:54,659 : INFO : collected 40137 word types and 3430 unique tags from a corpus of 243409 examples and 2018791 words\n",
            "2018-02-13 23:40:54,661 : INFO : Loading a fresh vocabulary\n",
            "2018-02-13 23:40:54,728 : INFO : min_count=5 retains 9182 unique words (22% of original 40137, drops 30955)\n",
            "2018-02-13 23:40:54,734 : INFO : min_count=5 leaves 1972909 word corpus (97% of original 2018791, drops 45882)\n",
            "2018-02-13 23:40:54,776 : INFO : deleting the raw counts dictionary of 40137 items\n",
            "2018-02-13 23:40:54,779 : INFO : sample=0.001 downsamples 58 most-common words\n",
            "2018-02-13 23:40:54,780 : INFO : downsampling leaves estimated 1260047 word corpus (63.9% of prior 1972909)\n",
            "2018-02-13 23:40:54,782 : INFO : estimated required memory for 9182 words and 100 dimensions: 13994600 bytes\n",
            "2018-02-13 23:40:54,828 : INFO : resetting layer weights\n",
            "2018-02-13 23:40:54,998 : INFO : training model with 7 workers on 9182 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=8\n",
            "2018-02-13 23:40:56,271 : INFO : PROGRESS: at 0.84% examples, 52328 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:40:57,371 : INFO : PROGRESS: at 2.21% examples, 75665 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:40:58,433 : INFO : PROGRESS: at 3.51% examples, 85464 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:40:59,484 : INFO : PROGRESS: at 4.73% examples, 88676 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:00,501 : INFO : PROGRESS: at 5.88% examples, 91517 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:01,539 : INFO : PROGRESS: at 7.06% examples, 94151 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:02,555 : INFO : PROGRESS: at 8.29% examples, 95615 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:03,604 : INFO : PROGRESS: at 9.53% examples, 96794 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:04,698 : INFO : PROGRESS: at 10.68% examples, 97403 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:05,709 : INFO : PROGRESS: at 11.78% examples, 97244 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:06,725 : INFO : PROGRESS: at 12.93% examples, 97129 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:07,800 : INFO : PROGRESS: at 14.16% examples, 97943 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:08,887 : INFO : PROGRESS: at 15.36% examples, 97202 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:09,979 : INFO : PROGRESS: at 16.54% examples, 96485 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:11,094 : INFO : PROGRESS: at 17.87% examples, 97432 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:12,165 : INFO : PROGRESS: at 18.94% examples, 96559 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:13,171 : INFO : PROGRESS: at 20.16% examples, 96938 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:14,324 : INFO : PROGRESS: at 21.47% examples, 96688 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:15,421 : INFO : PROGRESS: at 22.91% examples, 97217 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:16,605 : INFO : PROGRESS: at 24.31% examples, 97480 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:17,827 : INFO : PROGRESS: at 25.67% examples, 97683 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:18,901 : INFO : PROGRESS: at 27.02% examples, 98703 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:19,984 : INFO : PROGRESS: at 28.35% examples, 99052 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:21,040 : INFO : PROGRESS: at 29.48% examples, 98936 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:22,075 : INFO : PROGRESS: at 30.65% examples, 99293 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:23,080 : INFO : PROGRESS: at 31.85% examples, 99484 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:24,248 : INFO : PROGRESS: at 33.18% examples, 99443 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:25,375 : INFO : PROGRESS: at 34.52% examples, 99910 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:26,430 : INFO : PROGRESS: at 35.96% examples, 100089 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:27,446 : INFO : PROGRESS: at 37.09% examples, 99950 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:28,505 : INFO : PROGRESS: at 38.24% examples, 99820 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:29,628 : INFO : PROGRESS: at 39.69% examples, 100180 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:30,645 : INFO : PROGRESS: at 41.04% examples, 100380 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:31,656 : INFO : PROGRESS: at 42.22% examples, 100232 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:32,679 : INFO : PROGRESS: at 43.32% examples, 100100 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:33,685 : INFO : PROGRESS: at 44.54% examples, 100153 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:34,774 : INFO : PROGRESS: at 45.80% examples, 100299 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:35,782 : INFO : PROGRESS: at 46.79% examples, 100134 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:36,965 : INFO : PROGRESS: at 47.98% examples, 99872 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:38,064 : INFO : PROGRESS: at 49.28% examples, 99903 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:39,174 : INFO : PROGRESS: at 50.42% examples, 99910 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:40,231 : INFO : PROGRESS: at 51.48% examples, 99715 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:41,236 : INFO : PROGRESS: at 52.64% examples, 99642 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:42,323 : INFO : PROGRESS: at 53.98% examples, 99967 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:43,332 : INFO : PROGRESS: at 55.14% examples, 99869 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:44,436 : INFO : PROGRESS: at 56.32% examples, 99569 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:45,474 : INFO : PROGRESS: at 57.61% examples, 99818 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:46,566 : INFO : PROGRESS: at 58.85% examples, 99758 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:47,723 : INFO : PROGRESS: at 60.05% examples, 99513 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:48,763 : INFO : PROGRESS: at 61.37% examples, 99590 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:49,804 : INFO : PROGRESS: at 62.37% examples, 99177 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:50,835 : INFO : PROGRESS: at 63.57% examples, 99222 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:51,873 : INFO : PROGRESS: at 64.88% examples, 99398 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:52,911 : INFO : PROGRESS: at 65.75% examples, 98992 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:41:53,938 : INFO : PROGRESS: at 66.93% examples, 99170 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:55,016 : INFO : PROGRESS: at 68.14% examples, 99167 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:56,025 : INFO : PROGRESS: at 69.22% examples, 99057 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:57,055 : INFO : PROGRESS: at 70.36% examples, 99212 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:58,056 : INFO : PROGRESS: at 71.43% examples, 99179 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:41:59,083 : INFO : PROGRESS: at 72.59% examples, 99091 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:42:00,206 : INFO : PROGRESS: at 73.85% examples, 99150 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:42:01,219 : INFO : PROGRESS: at 75.22% examples, 99364 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:42:02,309 : INFO : PROGRESS: at 76.27% examples, 99039 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:42:03,387 : INFO : PROGRESS: at 77.58% examples, 99172 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:42:04,601 : INFO : PROGRESS: at 78.91% examples, 99074 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:42:05,614 : INFO : PROGRESS: at 80.20% examples, 99223 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:42:06,707 : INFO : PROGRESS: at 81.41% examples, 99088 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:42:07,840 : INFO : PROGRESS: at 82.56% examples, 98761 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:42:08,886 : INFO : PROGRESS: at 83.73% examples, 98802 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:42:10,009 : INFO : PROGRESS: at 85.10% examples, 98948 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:42:11,046 : INFO : PROGRESS: at 86.15% examples, 98849 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:42:12,121 : INFO : PROGRESS: at 87.25% examples, 98840 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:42:13,247 : INFO : PROGRESS: at 88.67% examples, 98989 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:42:14,366 : INFO : PROGRESS: at 89.97% examples, 99104 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:42:15,498 : INFO : PROGRESS: at 91.27% examples, 99221 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:42:16,618 : INFO : PROGRESS: at 92.64% examples, 99260 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:42:17,631 : INFO : PROGRESS: at 93.89% examples, 99434 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:42:18,630 : INFO : PROGRESS: at 95.04% examples, 99394 words/s, in_qsize 14, out_qsize 0\n",
            "2018-02-13 23:42:19,732 : INFO : PROGRESS: at 96.32% examples, 99331 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:42:20,759 : INFO : PROGRESS: at 97.61% examples, 99494 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-13 23:42:21,944 : INFO : PROGRESS: at 98.94% examples, 99448 words/s, in_qsize 11, out_qsize 0\n",
            "2018-02-13 23:42:22,356 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2018-02-13 23:42:22,373 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2018-02-13 23:42:22,427 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2018-02-13 23:42:22,455 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-02-13 23:42:22,503 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-02-13 23:42:22,522 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-02-13 23:42:22,531 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-02-13 23:42:22,533 : INFO : training on 10093955 raw words (8735873 effective words) took 87.5s, 99809 effective words/s\n"
          ]
        }
      ],
      "execution_count": 188,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('doc2vec_structured.m')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-13 23:55:30,659 : INFO : saving Doc2Vec object under doc2vec_simple_model.m, separately None\n",
            "2018-02-13 23:55:30,663 : INFO : not storing attribute syn0norm\n",
            "2018-02-13 23:55:30,664 : INFO : not storing attribute cum_table\n",
            "2018-02-13 23:55:30,803 : INFO : saved doc2vec_simple_model.m\n"
          ]
        }
      ],
      "execution_count": 198,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets see which is the most similiar to a chosen document\n",
        "\nmodel.docvecs.most_similar(200) "
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 197,
          "data": {
            "text/plain": [
              "[(u'151', 0.9998267889022827),\n",
              " ('CALIPSO Lidar Level 2 aerosol profile data using the CALIPSO Lidar Ratio selection algorithm (CAL_LID_L2_05kmAPro-Prov-V3-30)',\n",
              "  0.9759185314178467),\n",
              " (u'154', 0.9758481979370117),\n",
              " (u'156', 0.9694593548774719),\n",
              " ('CALIPSO Lidar Level 2 Cloud Profile data (CAL_LID_L2_05kmCPro-Prov-V3-30)',\n",
              "  0.9688910245895386),\n",
              " (u'169', 0.9673362374305725),\n",
              " ('CERES Single Scanner Satellite Footprint, TOA, Surface Fluxes and Clouds (SSF) data in HDF (CER_SSF_NPP-FM5-VIIRS_Edition1A)',\n",
              "  0.9670361280441284),\n",
              " ('CALIPSO Lidar Level 2 5 km aerosol layer data (CAL_LID_L2_05kmALay-Prov-V3-30)',\n",
              "  0.966292142868042),\n",
              " (u'153', 0.9662625789642334),\n",
              " ('CALIPSO Lidar Level 2 5 km cloud layer data (CAL_LID_L2_05kmCLay-Prov-V3-30)',\n",
              "  0.9644289016723633)]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 197,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print metadata[200]['Collection']['ShortName']"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGDL\n"
          ]
        }
      ],
      "execution_count": 261,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This works, but what would have happened if we had used a different representation of documents that captured less of the structure?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 203,
          "data": {
            "text/plain": [
              "u'20030123t170000 applicationecho10xml usa   20120531t000000 cryosat2 doppler orbitography by radiopositioning integrated on satellite rangerate observation data cycle format from nasa cddis jason1 archiver telephone doris receiver doris receiver haiyang2a spot5 doris beacon doris receiver   c1000000000cddis 3016146542 topexposeidon cryosat2 ocean topography experiment the doppler orbitography by radiopositioning integrated on satellite doris was developed by the centre national detudes spatiales cnes with cooperation from other french government agencies the system was developed to provide precise orbit determination and high accuracy location of ground beacons for point positioning doris is a dualfrequency doppler system that has been included as an experiment on various space missions such as topexposeidon spot2 3 4 and 5 envisat and jason satellites unlike many other navigation systems doris is based on an uplink device the receivers are on board the satellite with the transmitters are on the ground this creates a centralized system in which the complete set of observations is downloaded by the satellite to the ground center from where they are distributed after editing and processing an accurate measurment is made of the doppler shift on radiofrequency signals emitted by the ground beacons and received on the spacecraft spot4 greenbelt none ground stations doris receiver cddis_doris_data_cycle jason2   cddis_doris_data   jason1 crustal dynamics data information system spot2   cddis_doris_data_cycle cddisgsfc international doris service doris receiver systeme probatoire pour lobservation de la terre4 spot3 none cartesian   systeme probatoire pour lobservation de la terre2   hy2a true ground stations noll cartesian   ids nasa goddard space flight center code 690 3016146015 systeme probatoire pour lobservation de la terre5 carey doris receiver doris receiver careyenollnasagov     md doris receiver doris receiver systeme probatoire pour lobservation de la terre3 fax 19900331t000000 jason2'"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 203,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "# Parallelize for speed\n",
        "pool = multiprocessing.Pool()\n",
        "documents = pool.map(struct2Doc, metadata)"
      ],
      "outputs": [],
      "execution_count": 217,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import doc2vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "# We need to feed it labeled sentences\n",
        "idx = 0\n",
        "doc_sentences2 = []\n",
        "for document in documents:\n",
        "    ln = metadata[idx]['Collection']['LongName']\n",
        "    sentence = filter(None, document.split(' '))\n",
        "    td = TaggedDocument(words=sentence, tags=[unicode(idx), ln])\n",
        "    doc_sentences2.append(td)\n",
        "    idx += 1"
      ],
      "outputs": [],
      "execution_count": 220,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_simplified = doc2vec.Doc2Vec(doc_sentences2, size=100, window=8, min_count=5, workers=7)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-14 00:12:24,561 : INFO : collecting all words and their counts\n",
            "2018-02-14 00:12:24,566 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
            "2018-02-14 00:12:25,026 : INFO : collected 32366 word types and 3430 unique tags from a corpus of 2516 examples and 1081725 words\n",
            "2018-02-14 00:12:25,027 : INFO : Loading a fresh vocabulary\n",
            "2018-02-14 00:12:25,099 : INFO : min_count=5 retains 8858 unique words (27% of original 32366, drops 23508)\n",
            "2018-02-14 00:12:25,100 : INFO : min_count=5 leaves 1045917 word corpus (96% of original 1081725, drops 35808)\n",
            "2018-02-14 00:12:25,141 : INFO : deleting the raw counts dictionary of 32366 items\n",
            "2018-02-14 00:12:25,144 : INFO : sample=0.001 downsamples 49 most-common words\n",
            "2018-02-14 00:12:25,145 : INFO : downsampling leaves estimated 881349 word corpus (84.3% of prior 1045917)\n",
            "2018-02-14 00:12:25,147 : INFO : estimated required memory for 8858 words and 100 dimensions: 13573400 bytes\n",
            "2018-02-14 00:12:25,187 : INFO : resetting layer weights\n",
            "2018-02-14 00:12:25,344 : INFO : training model with 7 workers on 8858 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=8\n",
            "2018-02-14 00:12:26,361 : INFO : PROGRESS: at 25.00% examples, 1101617 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-14 00:12:27,364 : INFO : PROGRESS: at 51.05% examples, 1131100 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-14 00:12:28,369 : INFO : PROGRESS: at 80.13% examples, 1176270 words/s, in_qsize 13, out_qsize 0\n",
            "2018-02-14 00:12:29,083 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2018-02-14 00:12:29,088 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2018-02-14 00:12:29,101 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2018-02-14 00:12:29,106 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-02-14 00:12:29,110 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-02-14 00:12:29,115 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-02-14 00:12:29,119 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-02-14 00:12:29,123 : INFO : training on 5408625 raw words (4432352 effective words) took 3.8s, 1174559 effective words/s\n"
          ]
        }
      ],
      "execution_count": 221,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_simplified.save('doc2vec_simple.m')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-14 00:13:49,948 : INFO : saving Doc2Vec object under doc2vec_simple_model.m, separately None\n",
            "2018-02-14 00:13:49,952 : INFO : not storing attribute syn0norm\n",
            "2018-02-14 00:13:49,954 : INFO : not storing attribute cum_table\n",
            "2018-02-14 00:13:50,092 : INFO : saved doc2vec_simple_model.m\n"
          ]
        }
      ],
      "execution_count": 222,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare how this version of documents compares"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_simplified.docvecs.most_similar(200) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-14 00:14:26,897 : INFO : precomputing L2-norms of doc weight vectors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 224,
          "data": {
            "text/plain": [
              "[(u'151', 0.9997702836990356),\n",
              " ('CALIPSO Lidar Level 2 5 km aerosol layer data (CAL_LID_L2_05kmALay-Prov-V3-30)',\n",
              "  0.9831189513206482),\n",
              " (u'153', 0.9828567504882812),\n",
              " (u'157', 0.9820994138717651),\n",
              " ('CALIPSO Lidar Level 2 1/3 km cloud layer data (CAL_LID_L2_333mCLay-ValStage1-V3-30)',\n",
              "  0.9817156791687012),\n",
              " ('CALIPSO Lidar Level 2 Cloud Profile data (CAL_LID_L2_05kmCPro-Prov-V3-30)',\n",
              "  0.9773738980293274),\n",
              " (u'156', 0.9772941470146179),\n",
              " (u'154', 0.9766090512275696),\n",
              " ('CALIPSO Lidar Level 2 aerosol profile data using the CALIPSO Lidar Ratio selection algorithm (CAL_LID_L2_05kmAPro-Prov-V3-30)',\n",
              "  0.9758360981941223),\n",
              " (u'159', 0.9728275537490845)]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 224,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.docvecs.most_similar(200)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 225,
          "data": {
            "text/plain": [
              "[(u'151', 0.9998267889022827),\n",
              " ('CALIPSO Lidar Level 2 aerosol profile data using the CALIPSO Lidar Ratio selection algorithm (CAL_LID_L2_05kmAPro-Prov-V3-30)',\n",
              "  0.9759185314178467),\n",
              " (u'154', 0.9758481979370117),\n",
              " (u'156', 0.9694593548774719),\n",
              " ('CALIPSO Lidar Level 2 Cloud Profile data (CAL_LID_L2_05kmCPro-Prov-V3-30)',\n",
              "  0.9688910245895386),\n",
              " (u'169', 0.9673362374305725),\n",
              " ('CERES Single Scanner Satellite Footprint, TOA, Surface Fluxes and Clouds (SSF) data in HDF (CER_SSF_NPP-FM5-VIIRS_Edition1A)',\n",
              "  0.9670361280441284),\n",
              " ('CALIPSO Lidar Level 2 5 km aerosol layer data (CAL_LID_L2_05kmALay-Prov-V3-30)',\n",
              "  0.966292142868042),\n",
              " (u'153', 0.9662625789642334),\n",
              " ('CALIPSO Lidar Level 2 5 km cloud layer data (CAL_LID_L2_05kmCLay-Prov-V3-30)',\n",
              "  0.9644289016723633)]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 225,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks about the same."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use LDA on the data. First we have to make a corpus."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "\n",
        "plain_sentences = [filter(None, document.split(' ')) for document in documents]\n",
        "dictionary = corpora.Dictionary(plain_sentences)\n",
        "corpus = [dictionary.doc2bow(sentence) for sentence in plain_sentences]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-14 00:37:42,361 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
            "2018-02-14 00:37:43,851 : INFO : built Dictionary(32366 unique tokens: [u'tilton', u'fermanv1', u'woods', u'netcdf', u'spiders']...) from 2516 documents (total 1081725 corpus positions)\n"
          ]
        }
      ],
      "execution_count": 230,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 246,
          "data": {
            "text/plain": [
              "u'jason'"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 246,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=100, id2word=dictionary)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-14 00:56:22,606 : INFO : using symmetric alpha at 0.01\n",
            "2018-02-14 00:56:22,609 : INFO : using symmetric eta at 3.08966199098e-05\n",
            "2018-02-14 00:56:22,621 : INFO : using serial LDA version on this node\n",
            "2018-02-14 00:56:40,970 : INFO : running online (single-pass) LDA training, 100 topics, 1 passes over the supplied corpus of 2516 documents, updating model once every 2000 documents, evaluating perplexity every 2516 documents, iterating 50x with a convergence threshold of 0.001000\n",
            "2018-02-14 00:56:40,972 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "2018-02-14 00:56:40,978 : INFO : PROGRESS: pass 0, at document #2000/2516\n",
            "2018-02-14 00:56:53,571 : INFO : merging changes from 2000 documents into a model of 2516 documents\n",
            "2018-02-14 00:56:54,800 : INFO : topic #14 (0.010): 0.020*\"and\" + 0.019*\"the\" + 0.013*\"data\" + 0.012*\"00\" + 0.011*\"earth\" + 0.011*\"ceres\" + 0.011*\"nasa\" + 0.008*\"provided\" + 0.007*\"radiometer\" + 0.006*\"in\"\n",
            "2018-02-14 00:56:54,804 : INFO : topic #90 (0.010): 0.029*\"the\" + 0.018*\"and\" + 0.017*\"not\" + 0.014*\"of\" + 0.013*\"provided\" + 0.013*\"data\" + 0.013*\"00\" + 0.012*\"science\" + 0.011*\"earth\" + 0.009*\"scar\"\n",
            "2018-02-14 00:56:54,806 : INFO : topic #76 (0.010): 0.022*\"the\" + 0.018*\"of\" + 0.017*\"data\" + 0.012*\"and\" + 0.010*\"earth\" + 0.009*\"00\" + 0.008*\"nasa\" + 0.007*\"to\" + 0.006*\"a\" + 0.005*\"for\"\n",
            "2018-02-14 00:56:54,808 : INFO : topic #87 (0.010): 0.032*\"the\" + 0.018*\"data\" + 0.015*\"and\" + 0.012*\"of\" + 0.012*\"00\" + 0.011*\"earth\" + 0.008*\"to\" + 0.008*\"nasa\" + 0.007*\"in\" + 0.007*\"science\"\n",
            "2018-02-14 00:56:54,810 : INFO : topic #47 (0.010): 0.025*\"data\" + 0.025*\"the\" + 0.020*\"earth\" + 0.018*\"science\" + 0.018*\"not\" + 0.016*\"provided\" + 0.014*\"and\" + 0.013*\"of\" + 0.011*\"00\" + 0.008*\"atmosphere\"\n",
            "2018-02-14 00:56:54,824 : INFO : topic diff=72.035128, rho=1.000000\n",
            "2018-02-14 00:57:04,051 : INFO : -13.326 per-word bound, 10266.0 perplexity estimate based on a held-out corpus of 516 documents with 205081 words\n",
            "2018-02-14 00:57:04,053 : INFO : PROGRESS: pass 0, at document #2516/2516\n",
            "2018-02-14 00:57:06,681 : INFO : merging changes from 516 documents into a model of 2516 documents\n",
            "2018-02-14 00:57:07,640 : INFO : topic #46 (0.010): 0.050*\"cloud\" + 0.042*\"atmosphere\" + 0.038*\"earth\" + 0.036*\"science\" + 0.019*\"clouds\" + 0.018*\"the\" + 0.017*\"modis\" + 0.016*\"and\" + 0.015*\"properties\" + 0.013*\"atmospheric\"\n",
            "2018-02-14 00:57:07,644 : INFO : topic #70 (0.010): 0.034*\"data\" + 0.030*\"the\" + 0.028*\"documentation\" + 0.026*\"and\" + 0.020*\"set\" + 0.015*\"of\" + 0.013*\"earth\" + 0.013*\"science\" + 0.012*\"00\" + 0.012*\"boreas\"\n",
            "2018-02-14 00:57:07,646 : INFO : topic #33 (0.010): 0.028*\"the\" + 0.013*\"earth\" + 0.013*\"and\" + 0.013*\"data\" + 0.011*\"00\" + 0.011*\"of\" + 0.008*\"to\" + 0.007*\"for\" + 0.007*\"science\" + 0.006*\"atmosphere\"\n",
            "2018-02-14 00:57:07,648 : INFO : topic #69 (0.010): 0.046*\"the\" + 0.019*\"and\" + 0.018*\"data\" + 0.018*\"of\" + 0.013*\"not\" + 0.012*\"provided\" + 0.010*\"to\" + 0.010*\"00\" + 0.009*\"in\" + 0.008*\"for\"\n",
            "2018-02-14 00:57:07,649 : INFO : topic #47 (0.010): 0.028*\"data\" + 0.021*\"earth\" + 0.020*\"science\" + 0.019*\"the\" + 0.015*\"atmosphere\" + 0.015*\"not\" + 0.015*\"and\" + 0.014*\"00\" + 0.013*\"provided\" + 0.012*\"atmospheric\"\n",
            "2018-02-14 00:57:07,665 : INFO : topic diff=7.126786, rho=0.707107\n"
          ]
        }
      ],
      "execution_count": 248,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda.print_topics(10)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-14 00:58:57,109 : INFO : topic #93 (0.010): 0.014*\"earth\" + 0.011*\"\n",
            "\" + 0.010*\"land\" + 0.009*\"data\" + 0.009*\"provided\" + 0.008*\"not\" + 0.008*\"science\" + 0.007*\"the\" + 0.006*\"use\" + 0.006*\"cover\"\n",
            "2018-02-14 00:58:57,111 : INFO : topic #38 (0.010): 0.016*\"the\" + 0.014*\"data\" + 0.014*\"of\" + 0.014*\"and\" + 0.011*\"earth\" + 0.008*\"science\" + 0.007*\"00\" + 0.006*\"surface\" + 0.006*\"in\" + 0.005*\"es\"\n",
            "2018-02-14 00:58:57,113 : INFO : topic #36 (0.010): 0.028*\"iris\" + 0.018*\"data\" + 0.017*\"earth\" + 0.016*\"the\" + 0.015*\"science\" + 0.012*\"of\" + 0.012*\"and\" + 0.010*\"a\" + 0.010*\"00\" + 0.010*\"land\"\n",
            "2018-02-14 00:58:57,115 : INFO : topic #37 (0.010): 0.030*\"data\" + 0.028*\"documentation\" + 0.025*\"set\" + 0.023*\"ornl\" + 0.022*\"00z\" + 0.021*\"daac\" + 0.018*\"10\" + 0.018*\"ornl_daac\" + 0.017*\"oak\" + 0.017*\"ridge\"\n",
            "2018-02-14 00:58:57,117 : INFO : topic #20 (0.010): 0.027*\"the\" + 0.026*\"and\" + 0.021*\"of\" + 0.020*\"water\" + 0.018*\"data\" + 0.017*\"provided\" + 0.015*\"risks\" + 0.014*\"earth\" + 0.014*\"science\" + 0.013*\"00\"\n",
            "2018-02-14 00:58:57,119 : INFO : topic #91 (0.010): 0.052*\"the\" + 0.018*\"of\" + 0.017*\"earth\" + 0.016*\"data\" + 0.014*\"for\" + 0.013*\"to\" + 0.011*\"and\" + 0.009*\"science\" + 0.009*\"string\" + 0.008*\"a\"\n",
            "2018-02-14 00:58:57,121 : INFO : topic #87 (0.010): 0.028*\"the\" + 0.017*\"nee\" + 0.017*\"data\" + 0.014*\"and\" + 0.012*\"20t08\" + 0.011*\"of\" + 0.010*\"00\" + 0.010*\"earth\" + 0.007*\"to\" + 0.006*\"nasa\"\n",
            "2018-02-14 00:58:57,122 : INFO : topic #25 (0.010): 0.045*\"fertilizer\" + 0.018*\"and\" + 0.016*\"image\" + 0.015*\"the\" + 0.014*\"data\" + 0.010*\"00z\" + 0.009*\"p\" + 0.009*\"daac\" + 0.009*\"for\" + 0.008*\"soil\"\n",
            "2018-02-14 00:58:57,124 : INFO : topic #98 (0.010): 0.028*\"the\" + 0.022*\"and\" + 0.014*\"of\" + 0.014*\"not\" + 0.013*\"imaging\" + 0.013*\"data\" + 0.013*\"provided\" + 0.010*\"for\" + 0.010*\"earth\" + 0.009*\"00\"\n",
            "2018-02-14 00:58:57,126 : INFO : topic #55 (0.010): 0.028*\"the\" + 0.021*\"data\" + 0.020*\"and\" + 0.017*\"modis\" + 0.015*\"of\" + 0.014*\"00\" + 0.014*\"earth\" + 0.010*\"science\" + 0.010*\"a\" + 0.010*\"for\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 258,
          "data": {
            "text/plain": [
              "[(93,\n",
              "  u'0.014*\"earth\" + 0.011*\"\\n\" + 0.010*\"land\" + 0.009*\"data\" + 0.009*\"provided\" + 0.008*\"not\" + 0.008*\"science\" + 0.007*\"the\" + 0.006*\"use\" + 0.006*\"cover\"'),\n",
              " (38,\n",
              "  u'0.016*\"the\" + 0.014*\"data\" + 0.014*\"of\" + 0.014*\"and\" + 0.011*\"earth\" + 0.008*\"science\" + 0.007*\"00\" + 0.006*\"surface\" + 0.006*\"in\" + 0.005*\"es\"'),\n",
              " (36,\n",
              "  u'0.028*\"iris\" + 0.018*\"data\" + 0.017*\"earth\" + 0.016*\"the\" + 0.015*\"science\" + 0.012*\"of\" + 0.012*\"and\" + 0.010*\"a\" + 0.010*\"00\" + 0.010*\"land\"'),\n",
              " (37,\n",
              "  u'0.030*\"data\" + 0.028*\"documentation\" + 0.025*\"set\" + 0.023*\"ornl\" + 0.022*\"00z\" + 0.021*\"daac\" + 0.018*\"10\" + 0.018*\"ornl_daac\" + 0.017*\"oak\" + 0.017*\"ridge\"'),\n",
              " (20,\n",
              "  u'0.027*\"the\" + 0.026*\"and\" + 0.021*\"of\" + 0.020*\"water\" + 0.018*\"data\" + 0.017*\"provided\" + 0.015*\"risks\" + 0.014*\"earth\" + 0.014*\"science\" + 0.013*\"00\"'),\n",
              " (91,\n",
              "  u'0.052*\"the\" + 0.018*\"of\" + 0.017*\"earth\" + 0.016*\"data\" + 0.014*\"for\" + 0.013*\"to\" + 0.011*\"and\" + 0.009*\"science\" + 0.009*\"string\" + 0.008*\"a\"'),\n",
              " (87,\n",
              "  u'0.028*\"the\" + 0.017*\"nee\" + 0.017*\"data\" + 0.014*\"and\" + 0.012*\"20t08\" + 0.011*\"of\" + 0.010*\"00\" + 0.010*\"earth\" + 0.007*\"to\" + 0.006*\"nasa\"'),\n",
              " (25,\n",
              "  u'0.045*\"fertilizer\" + 0.018*\"and\" + 0.016*\"image\" + 0.015*\"the\" + 0.014*\"data\" + 0.010*\"00z\" + 0.009*\"p\" + 0.009*\"daac\" + 0.009*\"for\" + 0.008*\"soil\"'),\n",
              " (98,\n",
              "  u'0.028*\"the\" + 0.022*\"and\" + 0.014*\"of\" + 0.014*\"not\" + 0.013*\"imaging\" + 0.013*\"data\" + 0.013*\"provided\" + 0.010*\"for\" + 0.010*\"earth\" + 0.009*\"00\"'),\n",
              " (55,\n",
              "  u'0.028*\"the\" + 0.021*\"data\" + 0.020*\"and\" + 0.017*\"modis\" + 0.015*\"of\" + 0.014*\"00\" + 0.014*\"earth\" + 0.010*\"science\" + 0.010*\"a\" + 0.010*\"for\"')]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 258,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "topic #25 (0.010): 0.045*\"fertilizer\" + 0.018*\"and\" + 0.016*\"image\" + 0.015*\"the\" + 0.014*\"data\" + 0.010*\"00z\" + 0.009*\"p\" + 0.009*\"daac\" + 0.009*\"for\" + 0.008*\"soil\""
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly this needs a lot more fine-tuning and removal of common words."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "lda.save('lda_simple.m')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2018-02-14 01:11:54,553 : INFO : saving LdaState object under lda_simple.m.state, separately None\n",
            "2018-02-14 01:11:54,637 : INFO : saved lda_simple.m.state\n",
            "2018-02-14 01:11:54,746 : INFO : saving LdaModel object under lda_simple.m, separately ['expElogbeta', 'sstats']\n",
            "2018-02-14 01:11:54,748 : INFO : not storing attribute id2word\n",
            "2018-02-14 01:11:54,752 : INFO : storing np array 'expElogbeta' to lda_simple.m.expElogbeta.npy\n",
            "2018-02-14 01:11:54,825 : INFO : not storing attribute state\n",
            "2018-02-14 01:11:54,828 : INFO : not storing attribute dispatcher\n",
            "2018-02-14 01:11:54,831 : INFO : saved lda_simple.m\n"
          ]
        }
      ],
      "execution_count": 259,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "language": "python",
      "display_name": "Python 2"
    },
    "kernel_info": {
      "name": "python2"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.14",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    },
    "nteract": {
      "version": "0.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}